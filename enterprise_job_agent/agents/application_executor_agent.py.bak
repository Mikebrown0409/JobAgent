"""Application Executor Agent for filling and submitting job applications."""

import logging
import asyncio
import json
import re
import os
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
from difflib import SequenceMatcher
from crewai import Agent

from enterprise_job_agent.core.action_executor import ActionExecutor, ActionContext
from enterprise_job_agent.core.diagnostics_manager import DiagnosticsManager
from enterprise_job_agent.tools.field_identifier import FieldInfo, FieldType
from enterprise_job_agent.tools.dropdown_matcher import DropdownMatcher
from enterprise_job_agent.tools.form_interaction import FormInteraction

logger = logging.getLogger(__name__)

@dataclass
class ExecutionResult:
    """Result of an execution operation."""
    success: bool
    stage_name: str
    field_results: Dict[str, Tuple[bool, Optional[str]]]
    error: Optional[str] = None

SYSTEM_PROMPT = """You are an expert Application Execution Specialist focusing on job applications.

TASK:
Execute form filling operations with precision and adaptability to complete job applications successfully.

YOUR EXPERTISE:
- Executing form filling strategies with technical precision
- Navigating complex multi-page application flows
- Handling all form field types (text, dropdowns, checkboxes, file uploads)
- Overcoming common application obstacles and validation issues
- Adapting to unexpected form behaviors

APPROACH:
1. Follow a strategic sequence (required fields first, then important fields, finally optional fields)
2. Handle each field type with appropriate techniques
3. Verify input success before proceeding
4. Detect and recover from errors immediately
5. Ensure all required fields are completed before submission

TECHNICAL CAPABILITIES:
- Text inputs: Clear and accurate data entry
- Dropdowns: Find closest matching option using fuzzy matching
- Checkboxes/Radio buttons: Select appropriate values
- File uploads: Ensure proper file paths and formats
- Specialized fields: Format properly (dates, phone numbers, etc.)
- iframe handling: Navigate between frames when needed

ALWAYS STRUCTURE YOUR EXECUTION PLAN AS JSON following the exact schema provided in the task.
"""

class ApplicationExecutorAgent:
    """Creates an agent specialized in form filling and submission."""
    
    def __init__(
        self, 
        action_executor: Optional[ActionExecutor] = None, 
        dropdown_matcher: Optional[DropdownMatcher] = None,
        form_interaction: Optional[FormInteraction] = None,
        logger=None
    ):
        """Initialize the application executor agent.
        
        Args:
            action_executor: Action executor for form manipulation
            dropdown_matcher: Tool for smart dropdown option matching
            form_interaction: Tool for form interaction utilities
            logger: Optional logger instance
        """
        self.action_executor = action_executor or ActionExecutor()
        self.dropdown_matcher = dropdown_matcher or DropdownMatcher()
        # Form interaction is optional and will be initialized if needed by action executor
        self.form_interaction = form_interaction
        self.logger = logger or logging.getLogger(__name__)
        
    def set_test_mode(self, test_mode: bool = True):
        """Set the test mode flag.
        
        Args:
            test_mode: Whether to run in test mode
        """
        if hasattr(self.action_executor, 'set_test_mode'):
            self.action_executor.set_test_mode(test_mode)
    
    @staticmethod
    def create(
        llm: Any,
        tools: List[Any] = None,
        verbose: bool = False
    ) -> Agent:
        """Create an Application Executor Agent."""
        return Agent(
            role="Application Execution Specialist",
            goal="Execute job applications with precision, overcoming obstacles and ensuring completion",
            backstory="""You are an expert in executing complex web-based job applications.
            You have deep technical knowledge of browser automation and form interactions.
            Your methodical approach ensures applications are filled correctly and completely,
            even when encountering unexpected challenges or unusual form structures.""",
            verbose=verbose,
            allow_delegation=False,
            tools=tools or [],
            llm=llm,
            system_prompt=SYSTEM_PROMPT
        )
    
    async def execute_plan(
        self,
        profile_mapping: Dict[str, Any],
        form_structure: Dict[str, Any],
        test_mode: bool = True
    ) -> Dict[str, Any]:
        """Execute the field population plan.
        
        Args:
            profile_mapping: Profile to form mapping
            form_structure: Form structure data
            test_mode: Whether to run in test mode
            
        Returns:
            Execution results
        """
        # Extract field mappings
        field_mappings = profile_mapping.get("field_mappings", [])
        
        # Initialize results
        field_results = []
        fields_filled = 0
        fields_failed = 0
        field_type_stats = {}
        
        # Track execution by field type
        for field_mapping in field_mappings:
            field_id = field_mapping.get("field_id")
            value = field_mapping.get("value", "")
            
            # Skip empty fields or recaptcha
            if not field_id or "recaptcha" in field_id.lower():
                continue
            
            # Get field type
            field_type = self._get_field_type(field_id, form_structure)
            
            # Initialize stats for this field type if not already tracked
            if field_type not in field_type_stats:
                field_type_stats[field_type] = {"total": 0, "success": 0}
            
            # Increment total count for this field type
            field_type_stats[field_type]["total"] += 1
            
            # Execute the field
            result = await self._execute_field(field_id, field_type, value, form_structure)
            
            # Set common fields for tracking
            result_with_meta = {
                "field_id": field_id,
                "field_type": field_type,
                "value": value,
                "success": result.get("success", False),
                "error": result.get("error", "")
            }
            
            # Update statistics
            if result.get("success", False):
                fields_filled += 1
                field_type_stats[field_type]["success"] += 1
            else:
                fields_failed += 1
            
            # Add result to tracking
            field_results.append(result_with_meta)
            
            # Short sleep between fields to avoid overwhelming the browser
            await asyncio.sleep(0.2)
        
        # Construct the final results
        execution_results = {
            "success": fields_failed == 0,
            "field_results": field_results,
            "fields_filled": fields_filled,
            "fields_failed": fields_failed,
            "field_type_stats": field_type_stats,
            "test_mode": test_mode
        }
        
        return execution_results
    
    def _determine_field_type(self, field_id: str, form_data: Dict[str, Any]) -> str:
        """Determine the field type from form data."""
        # List of common dropdown field patterns
        dropdown_patterns = [
            "school", "degree", "discipline", "education", "university", 
            "location", "country", "state", "city", "ethnicity", 
            "gender", "veteran_status", "disability_status", "race",
            "major", "title", "role", "position", "department"
        ]
        
        # First check if this is a commonly recognized dropdown field by pattern
        field_name_lower = field_id.lower()
        if any(pattern in field_name_lower for pattern in dropdown_patterns):
            # Check if we have options for this field - strong indicator it's a dropdown
            options = self._get_dropdown_options(field_id, form_data)
            if options:
                self.logger.debug(f"Field {field_id} identified as select based on pattern and available options")
                return "select"
            
            # Additional validation - check field structure for dropdown indicators
            # Check form elements
            for element in form_data.get("form_elements", []):
                if element.get("id") == field_id:
                    # Direct indicators in the element
                    if element.get("type") == "select" or "options" in element:
                        self.logger.debug(f"Field {field_id} identified as select from element structure")
                        return "select"
                    # Check for dropdown class indicators
                    element_class = element.get("class", "").lower()
                    if any(class_indicator in element_class for class_indicator in ["dropdown", "select", "combo"]):
                        self.logger.debug(f"Field {field_id} identified as select from class indicators")
                        return "select"
            
            # Even without direct evidence, education and location fields are almost always dropdowns
            high_confidence_dropdown_patterns = ["school", "degree", "discipline", "university", "education", "country", "state"]
            if any(pattern in field_name_lower for pattern in high_confidence_dropdown_patterns):
                self.logger.debug(f"Field {field_id} identified as select with high confidence based on naming pattern")
                return "select"
        
        # First check form_elements for direct type information
        for element in form_data.get("form_elements", []):
            if element.get("id") == field_id:
                element_type = element.get("type", "text")
                
                # Check for <select> tag or presence of options
                if element_type == "select" or "options" in element:
                    self.logger.debug(f"Field {field_id} identified as select from form_elements")
                    return "select"
                
                return element_type
        
        # Check in sections if available
        if "form_structure" in form_data:
            for section in form_data.get("form_structure", {}).get("sections", []):
                for field in section.get("fields", []):
                    if field.get("id") == field_id:
                        field_type = field.get("type", "text")
                        
                        # Check for <select> tag or presence of options
                        if field_type == "select" or "options" in field:
                            self.logger.debug(f"Field {field_id} identified as select from form_structure")
                            return "select"
                        
                        # Check field label for dropdown indicators
                        field_label = field.get("label", "").lower()
                        if field_label and any(pattern in field_label for pattern in dropdown_patterns):
                            self.logger.debug(f"Field {field_id} identified as select from label pattern: {field_label}")
                            return "select"
                            
                        return field_type
        
        # Look at HTML element tag if available
        if "element_tags" in form_data:
            element_tags = form_data.get("element_tags", {})
            if field_id in element_tags:
                tag = element_tags[field_id].lower()
                if tag == "select":
                    self.logger.debug(f"Field {field_id} identified as select from element_tags")
                    return "select"
                elif tag == "input":
                    input_type = form_data.get("input_types", {}).get(field_id, "text")
                    if input_type == "file":
                        return "file"
                    elif input_type in ["checkbox", "radio"]:
                        return "checkbox"
        
        # Check for HTML structure indicators
        html_structure = form_data.get("html_structure", {})
        if field_id in html_structure:
            field_html = html_structure.get(field_id, "").lower()
            if field_html and any(indicator in field_html for indicator in ["<select", "dropdown", "combobox"]):
                self.logger.debug(f"Field {field_id} identified as select from HTML structure")
                return "select"
            
        # Default to text
        return "text"
    
    def _get_selector_for_field(self, field_id: str, form_data: Dict[str, Any]) -> Optional[str]:
        """Get the selector for a field from form data."""
        # Check if the field has specific selector strategies in form_structure
        if "form_structure" in form_data:
            for section in form_data.get("form_structure", {}).get("sections", []):
                for field in section.get("fields", []):
                    if field.get("id") == field_id:
                        # Use the first selector strategy if available
                        strategies = field.get("selector_strategies", [])
                        
                        # School, degree, and discipline fields often need special handling
                        is_education_field = any(edu_field in field_id for edu_field in ["school", "degree", "discipline"])
                        
                        if strategies:
                            if len(strategies) > 1:
                                # If it's an education field or dropdown, try to find a better selector than just the ID
                                if is_education_field or field.get("type") == "select" or "options" in field:
                                    # Try different selector strategies
                                    for strategy in strategies:
                                        # Prefer selectors that look like complete CSS selectors rather than just IDs
                                        if strategy.startswith('#') and '--' in strategy:
                                            return strategy
                                        elif '[name=' in strategy or '[id=' in strategy:
                                            return strategy
                                
                                # Default to the second strategy (usually the ID selector)
                                return strategies[1]
                            else:
                                return strategies[0]
        
        # Check form_elements
        form_elements = form_data.get("form_elements", [])
        for element in form_elements:
            if element.get("id") == field_id:
                selector = element.get("selector")
                if selector:
                    return selector
                
                # For dropdowns, try to find a more specific selector
                if element.get("type") == "select" or "options" in element:
                    selectors = element.get("selector_strategies", [])
                    if selectors and len(selectors) > 0:
                        return selectors[0]
                
                return f"#{field_id}"  # Default to ID selector
        
        # Fall back to a simple ID selector
        return f"#{field_id}"

    def _importance_to_float(self, importance: str) -> float:
        """Convert importance string to float value."""
        importance_map = {
            "high": 1.0,
            "medium": 0.5,
            "low": 0.1
        }
        return importance_map.get(importance.lower(), 0.1)

    @staticmethod
    def create_execution_prompt(
        form_data: Dict[str, Any],
        field_mappings: Dict[str, Any],
        test_mode: bool = False
    ) -> str:
        """
        Create a prompt for executing a job application.
        
        Args:
            form_data: Form data and structure
            field_mappings: Field mappings from profile
            test_mode: Whether to run in test mode
            
        Returns:
            Execution prompt for the LLM
        """
        mode = "TEST MODE" if test_mode else "LIVE MODE"
        
        task_part = f"""
        TASK:
        Execute the following job application form in {mode}.
        """
        
        form_part = f"""
        FORM STRUCTURE:
        {json.dumps(form_data, indent=2)}
        """
        
        mappings_part = f"""
        FIELD MAPPINGS:
        {json.dumps(field_mappings, indent=2)}
        """
        
        instructions_part = """
        INSTRUCTIONS:
        1. Analyze the form structure and field mappings
        2. Create an execution plan that fills out the form efficiently
        3. Return your plan as a JSON array of steps, where each step has:
           - action: The action to take (e.g., "fill", "select", "upload")
           - field_id: The ID of the field to interact with
           - value: The value to input or select
           - options: Optional parameters for the action
        
        Example output format:
        [
            {
                "action": "fill",
                "field_id": "name",
                "value": "John Smith",
                "options": {}
            },
            {
                "action": "select",
                "field_id": "education",
                "value": "Bachelor's Degree",
                "options": {"exact_match": true}
            }
        ]
        """
        
        return task_part + form_part + mappings_part + instructions_part 

    def _get_dropdown_options(self, field_id: str, form_data: Dict[str, Any]) -> List[str]:
        """Get dropdown options for a field if available."""
        # Check form_elements
        form_elements = form_data.get("form_elements", [])
        for element in form_elements:
            if element.get("id") == field_id and "options" in element:
                return element.get("options", [])
        
        # Check in sections if available
        if "form_structure" in form_data:
            for section in form_data.get("form_structure", {}).get("sections", []):
                for field in section.get("fields", []):
                    if field.get("id") == field_id and "options" in field:
                        return field.get("options", [])
        
        # Look in validation_data
        if "validation_data" in form_data:
            field_validation = form_data.get("validation_data", {}).get(field_id, {})
            if "options" in field_validation:
                return field_validation.get("options", [])
        
        return [] 

    async def _handle_recaptcha_field(self, field_id: str, form_structure: Dict[str, Any]) -> Dict[str, Any]:
        """Handle reCAPTCHA fields specially.
        
        These fields require special handling as they're invisible and filled by the reCAPTCHA service.
        In test mode, we'll skip them; in production, we might attempt some form of workaround.
        
        Args:
            field_id: The field ID
            form_structure: The form structure
            
        Returns:
            Result dictionary
        """
        self.logger.info(f"Detected reCAPTCHA field: {field_id} - marking as handled in test mode")
        return {
            "field_id": field_id,
            "success": True,  # Pretend we handled it in test mode
            "field_type": "recaptcha",
            "value": "[RECAPTCHA FIELD - SKIPPED IN TEST MODE]",
            "error": None
        }

    def _get_field_type(self, field_id: str, form_structure: Dict[str, Any]) -> str:
        """Get the type of a form field from structure.
        
        Args:
            field_id: The field ID
            form_structure: The form structure
            
        Returns:
            Field type (e.g., 'text', 'select', 'file', 'textarea')
        """
        # First check in form_elements list
        if "form_elements" in form_structure:
            for element in form_structure.get("form_elements", []):
                if element.get("id") == field_id:
                    return element.get("type", "text")
        
        # Try to guess from HTML structure
        element_html = form_structure.get("html_structure", {}).get(field_id, "")
        
        if "textarea" in element_html.lower():
            return "textarea"
        elif 'type="file"' in element_html.lower():
            return "file"
        elif 'class="select__input"' in element_html.lower() or 'role="combobox"' in element_html.lower():
            return "select"
        elif "recaptcha" in field_id.lower() or "captcha" in field_id.lower():
            return "recaptcha"
        else:
            return "text" # Default to text input 

    async def _execute_field(self, field_id: str, field_type: str, value: str, form_structure: Dict) -> Dict[str, Any]:
        """Execute an action for a specific field.
        
        Args:
            field_id: ID of the field
            field_type: Type of the field (text, select, etc.)
            value: Value to set
            form_structure: Form structure data
            
        Returns:
            Dictionary with execution result
        """
        try:
            # Get the field's frame ID if applicable
            frame_id = self._get_field_frame(field_id, form_structure)
            
            # Format selector properly for CSS
            selector = f"#{field_id}"
            # Use attribute selector for numeric IDs
            if field_id.isdigit() or (field_id and field_id[0].isdigit()):
                selector = f"[id='{field_id}']"
            
            # Execute appropriate action based on field type
            if field_type == "select":
                # Get dropdown options from form structure
                dropdown_options = self._get_dropdown_options(field_id, form_structure)
                
                # If we have options and this is not a test run, find the best match
                if hasattr(self.action_executor, 'get_dropdown_options'):
                    # Try to get actual options from the dropdown
                    try:
                        actual_options = await self.action_executor.get_dropdown_options(selector, frame_id)
                        if actual_options:
                            self.logger.debug(f"Found {len(actual_options)} actual options for field {field_id}")
                            # Filter out non-options like descriptions or headers
                            cleaned_options = []
                            for option in actual_options:
                                # Skip extremely long text that's likely not an option
                                if len(option) < 100:
                                    cleaned_options.append(option)
                            
                            # Only use actual options if we found some valid ones
                            if cleaned_options:
                                self.logger.debug(f"Available options for {field_id}: {cleaned_options}")
                                dropdown_options = cleaned_options
                            else:
                                self.logger.warning(f"Found {len(actual_options)} options but they appear invalid for field {field_id}")
                    except Exception as e:
                        self.logger.warning(f"Could not get actual dropdown options for {field_id}: {str(e)}")
                
                # Determine the field context type for better matching
                context_type = None
                
                # Check field id for type hints
                field_id_lower = field_id.lower()
                if any(edu_term in field_id_lower for edu_term in ["school", "university", "college"]):
                    context_type = "education"
                elif any(degree_term in field_id_lower for degree_term in ["degree", "education"]):
                    context_type = "degree"
                elif any(discipline_term in field_id_lower for discipline_term in ["discipline", "major", "field", "study"]):
                    context_type = "discipline"
                elif any(location_term in field_id_lower for location_term in ["location", "city", "state", "country"]):
                    context_type = "location"
                elif any(demo_term in field_id_lower for demo_term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                    context_type = "demographic"
                
                # If dropdown options exist, try to find the best match
                if dropdown_options:
                    self.logger.debug(f"Available options for {field_id}: {dropdown_options}")
                    
                    # Special handling for location fields to improve matching
                    if context_type == "location" and "," in value:
                        # For locations like "San Francisco, California" check if any option contains both parts
                        city_state_parts = [part.strip() for part in value.split(",")]
                        if len(city_state_parts) >= 2:
                            # Try to find options that contain both parts
                            city, state = city_state_parts[0], city_state_parts[1]
                            matches = []
                            for option in dropdown_options:
                                if city.lower() in option.lower() and state.lower() in option.lower():
                                    matches.append((option, 0.9))
                            
                            # If we found matches, use the first one
                            if matches:
                                best_match, similarity = matches[0]
                                self.logger.info(f"Found location match '{best_match}' for '{value}' with {similarity:.1%} confidence")
                                value = best_match
                            else:
                                # If no combined match, try to match just the city or state
                                for part in city_state_parts:
                                    for option in dropdown_options:
                                        if part.lower() in option.lower():
                                            best_match, similarity = option, 0.7
                                            self.logger.info(f"Found partial location match '{best_match}' for '{value}' with {similarity:.1%} confidence")
                                            value = best_match
                                            break
                    
                    # First try exact match before using fuzzy matching
                    exact_match = next((option for option in dropdown_options if option.lower() == value.lower()), None)
                    if exact_match:
                        self.logger.info(f"Found exact match '{exact_match}' for '{value}'")
                        value = exact_match
                    # Special handling for Berkeley specifically in the main matching flow
                    elif "berkeley" in value.lower() and "university of california" in value.lower():
                        # Look for Berkeley in options explicitly
                        berkeley_options = []
                        for option in dropdown_options:
                            if "berkeley" in option.lower():
                                berkeley_options.append(option)
                                
                        if berkeley_options:
                            # Found a Berkeley option, use it directly
                            value = berkeley_options[0]
                            self.logger.info(f"Matched Berkeley specifically: '{value}'")
                        else:
                            # Fall back to regular matching but log the issue
                            self.logger.warning(f"Looking for Berkeley but not found in options. Will try regular matching.")
                            # Continue to regular matching below
                    
                    # If no exact match or Berkeley match, use regular matching
                    if not exact_match and not ("berkeley" in value.lower() and "university of california" in value.lower()):
                        # Use the dropdown matcher tool to find the best match
                        best_match, similarity = self.dropdown_matcher.find_best_match(
                            value, dropdown_options, field_type=context_type
                        )
                        
                        if best_match and similarity >= self.dropdown_matcher.match_threshold:
                            # Extra validation for Berkeley case to avoid false matches
                            if "berkeley" in value.lower() and "university of california" in value.lower():
                                if "berkeley" not in best_match.lower():
                                    self.logger.warning(f"Rejecting match '{best_match}' for Berkeley - doesn't contain 'berkeley'")
                                    # Look for any option containing Berkeley as a fallback
                                    berkeley_fallback = next((opt for opt in dropdown_options if "berkeley" in opt.lower()), None)
                                    if berkeley_fallback:
                                        value = berkeley_fallback
                                        self.logger.info(f"Using Berkeley fallback: '{value}'")
                                    # Otherwise continue with the original value and let the form handler deal with it
                                else:
                                    self.logger.info(f"Selected Berkeley match: '{best_match}' with {similarity:.1%} confidence")
                                    value = best_match
                            else:
                                self.logger.info(f"Selected '{best_match}' for '{value}' with {similarity:.1%} confidence")
                                value = best_match
                
                success = await self.action_executor.execute_action("select", selector, value, frame_id)
                if not success:
                    self.logger.error(f"Failed to execute select for field {field_id} of type {field_type}")
                    return {"success": False, "error": "Select action failed"}
                else:
                    self.logger.info(f"Successfully executed select for field {field_id} of type {field_type}")
                    return {"success": True}
                    
            elif field_type == "checkbox":
                # Convert value to boolean
                checked = self._parse_bool(value)
                success = await self.action_executor.execute_action("checkbox", selector, checked, frame_id)
                if not success:
                    self.logger.error(f"Failed to execute checkbox for field {field_id} of type {field_type}")
                    return {"success": False, "error": "Checkbox action failed"}
                else:
                    self.logger.info(f"Successfully executed checkbox for field {field_id} of type {field_type}")
                    return {"success": True}
                    
            elif field_type == "file":
                # Handle file uploads
                # Check if the path exists and is a file (not a directory)
                if value and not os.path.isfile(value):
                    self.logger.error(f"File path {value} for field {field_id} is not a valid file")
                    return {"success": False, "error": "Invalid file path"}
                
                success = await self.action_executor.execute_action("upload", selector, value, frame_id)
                if not success:
                    self.logger.error(f"Failed to execute file for field {field_id} of type {field_type}")
                    return {"success": False, "error": "File upload failed"}
                else:
                    self.logger.info(f"Successfully executed file for field {field_id} of type {field_type}")
                    return {"success": True}
                    
            elif field_type == "textarea":
                # Handle multiline text
                success = await self.action_executor.execute_action("fill", selector, value, frame_id)
                if not success:
                    self.logger.error(f"Failed to execute textarea for field {field_id} of type {field_type}")
                    return {"success": False, "error": "Text area fill failed"}
                else:
                    self.logger.info(f"Successfully executed textarea for field {field_id} of type {field_type}")
                    return {"success": True}
                    
            else:
                # Default to text input
                success = await self.action_executor.execute_action("fill", selector, value, frame_id)
                if not success:
                    self.logger.error(f"Failed to execute text for field {field_id} of type {field_type}")
                    return {"success": False, "error": "Text fill failed"}
                else:
                    self.logger.info(f"Successfully executed text for field {field_id} of type {field_type}")
                    return {"success": True}
                    
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
"""Application Executor Agent for filling and submitting job applications."""

import logging
import asyncio
import json
import re
import os
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
from difflib import SequenceMatcher
from crewai import Agent

from enterprise_job_agent.core.action_executor import ActionExecutor, ActionContext
from enterprise_job_agent.core.diagnostics_manager import DiagnosticsManager
from enterprise_job_agent.tools.field_identifier import FieldInfo, FieldType
from enterprise_job_agent.tools.dropdown_matcher import DropdownMatcher
from enterprise_job_agent.tools.form_interaction import FormInteraction

logger = logging.getLogger(__name__)

@dataclass
class ExecutionResult:
    """Result of an execution operation."""
    success: bool
    stage_name: str
    field_results: Dict[str, Tuple[bool, Optional[str]]]
    error: Optional[str] = None

SYSTEM_PROMPT = """You are an expert Application Execution Specialist focusing on job applications.

TASK:
Execute form filling operations with precision and adaptability to complete job applications successfully.

YOUR EXPERTISE:
- Executing form filling strategies with technical precision
- Navigating complex multi-page application flows
- Handling all form field types (text, dropdowns, checkboxes, file uploads)
- Overcoming common application obstacles and validation issues
- Adapting to unexpected form behaviors

APPROACH:
1. Follow a strategic sequence (required fields first, then important fields, finally optional fields)
2. Handle each field type with appropriate techniques
3. Verify input success before proceeding
4. Detect and recover from errors immediately
5. Ensure all required fields are completed before submission

TECHNICAL CAPABILITIES:
- Text inputs: Clear and accurate data entry
- Dropdowns: Find closest matching option using fuzzy matching
- Checkboxes/Radio buttons: Select appropriate values
- File uploads: Ensure proper file paths and formats
- Specialized fields: Format properly (dates, phone numbers, etc.)
- iframe handling: Navigate between frames when needed

ALWAYS STRUCTURE YOUR EXECUTION PLAN AS JSON following the exact schema provided in the task.
"""

class ApplicationExecutorAgent:
    """Creates an agent specialized in form filling and submission."""
    
    def __init__(
        self, 
        action_executor: Optional[ActionExecutor] = None, 
        dropdown_matcher: Optional[DropdownMatcher] = None,
        form_interaction: Optional[FormInteraction] = None,
        logger=None
    ):
        """Initialize the application executor agent.
        
        Args:
            action_executor: Action executor for form manipulation
            dropdown_matcher: Tool for smart dropdown option matching
            form_interaction: Tool for form interaction utilities
            logger: Optional logger instance
        """
        self.action_executor = action_executor or ActionExecutor()
        self.dropdown_matcher = dropdown_matcher or DropdownMatcher()
        # Form interaction is optional and will be initialized if needed by action executor
        self.form_interaction = form_interaction
        self.logger = logger or logging.getLogger(__name__)
        
    def set_test_mode(self, test_mode: bool = True):
        """Set the test mode flag.
        
        Args:
            test_mode: Whether to run in test mode
        """
        if hasattr(self.action_executor, 'set_test_mode'):
            self.action_executor.set_test_mode(test_mode)
    
    @staticmethod
    def create(
        llm: Any,
        tools: List[Any] = None,
        verbose: bool = False
    ) -> Agent:
        """Create an Application Executor Agent."""
        return Agent(
            role="Application Execution Specialist",
            goal="Execute job applications with precision, overcoming obstacles and ensuring completion",
            backstory="""You are an expert in executing complex web-based job applications.
            You have deep technical knowledge of browser automation and form interactions.
            Your methodical approach ensures applications are filled correctly and completely,
            even when encountering unexpected challenges or unusual form structures.""",
            verbose=verbose,
            allow_delegation=False,
            tools=tools or [],
            llm=llm,
            system_prompt=SYSTEM_PROMPT
        )
    
    async def execute_plan(
        self,
        profile_mapping: Dict[str, Any],
        form_structure: Dict[str, Any],
        test_mode: bool = True
    ) -> Dict[str, Any]:
        """Execute the field population plan.
        
        Args:
            profile_mapping: Profile to form mapping
            form_structure: Form structure data
            test_mode: Whether to run in test mode
            
        Returns:
            Execution results
        """
        # Extract field mappings
        field_mappings = profile_mapping.get("field_mappings", [])
        
        # Initialize results
        field_results = []
        fields_filled = 0
        fields_failed = 0
        field_type_stats = {}
        
        # Track execution by field type
        for field_mapping in field_mappings:
            field_id = field_mapping.get("field_id")
            value = field_mapping.get("value", "")
            
            # Skip empty fields or recaptcha
            if not field_id or "recaptcha" in field_id.lower():
                continue
            
            # Get field type
            field_type = self._get_field_type(field_id, form_structure)
            
            # Initialize stats for this field type if not already tracked
            if field_type not in field_type_stats:
                field_type_stats[field_type] = {"total": 0, "success": 0}
            
            # Increment total count for this field type
            field_type_stats[field_type]["total"] += 1
            
            # Execute the field
            result = await self._execute_field(field_id, field_type, value, form_structure)
            
            # Set common fields for tracking
            result_with_meta = {
                "field_id": field_id,
                "field_type": field_type,
                "value": value,
                "success": result.get("success", False),
                "error": result.get("error", "")
            }
            
            # Update statistics
            if result.get("success", False):
                fields_filled += 1
                field_type_stats[field_type]["success"] += 1
            else:
                fields_failed += 1
            
            # Add result to tracking
            field_results.append(result_with_meta)
            
            # Short sleep between fields to avoid overwhelming the browser
            await asyncio.sleep(0.2)
        
        # Construct the final results
        execution_results = {
            "success": fields_failed == 0,
            "field_results": field_results,
            "fields_filled": fields_filled,
            "fields_failed": fields_failed,
            "field_type_stats": field_type_stats,
            "test_mode": test_mode
        }
        
        return execution_results
    
    def _determine_field_type(self, field_id: str, form_data: Dict[str, Any]) -> str:
        """Determine the field type from form data."""
        # List of common dropdown field patterns
        dropdown_patterns = [
            "school", "degree", "discipline", "education", "university", 
            "location", "country", "state", "city", "ethnicity", 
            "gender", "veteran_status", "disability_status", "race",
            "major", "title", "role", "position", "department"
        ]
        
        # First check if this is a commonly recognized dropdown field by pattern
        field_name_lower = field_id.lower()
        if any(pattern in field_name_lower for pattern in dropdown_patterns):
            # Check if we have options for this field - strong indicator it's a dropdown
            options = self._get_dropdown_options(field_id, form_data)
            if options:
                self.logger.debug(f"Field {field_id} identified as select based on pattern and available options")
                return "select"
            
            # Additional validation - check field structure for dropdown indicators
            # Check form elements
            for element in form_data.get("form_elements", []):
                if element.get("id") == field_id:
                    # Direct indicators in the element
                    if element.get("type") == "select" or "options" in element:
                        self.logger.debug(f"Field {field_id} identified as select from element structure")
                        return "select"
                    # Check for dropdown class indicators
                    element_class = element.get("class", "").lower()
                    if any(class_indicator in element_class for class_indicator in ["dropdown", "select", "combo"]):
                        self.logger.debug(f"Field {field_id} identified as select from class indicators")
                        return "select"
            
            # Even without direct evidence, education and location fields are almost always dropdowns
            high_confidence_dropdown_patterns = ["school", "degree", "discipline", "university", "education", "country", "state"]
            if any(pattern in field_name_lower for pattern in high_confidence_dropdown_patterns):
                self.logger.debug(f"Field {field_id} identified as select with high confidence based on naming pattern")
                return "select"
        
        # First check form_elements for direct type information
        for element in form_data.get("form_elements", []):
            if element.get("id") == field_id:
                element_type = element.get("type", "text")
                
                # Check for <select> tag or presence of options
                if element_type == "select" or "options" in element:
                    self.logger.debug(f"Field {field_id} identified as select from form_elements")
                    return "select"
                
                return element_type
        
        # Check in sections if available
        if "form_structure" in form_data:
            for section in form_data.get("form_structure", {}).get("sections", []):
                for field in section.get("fields", []):
                    if field.get("id") == field_id:
                        field_type = field.get("type", "text")
                        
                        # Check for <select> tag or presence of options
                        if field_type == "select" or "options" in field:
                            self.logger.debug(f"Field {field_id} identified as select from form_structure")
                            return "select"
                        
                        # Check field label for dropdown indicators
                        field_label = field.get("label", "").lower()
                        if field_label and any(pattern in field_label for pattern in dropdown_patterns):
                            self.logger.debug(f"Field {field_id} identified as select from label pattern: {field_label}")
                            return "select"
                            
                        return field_type
        
        # Look at HTML element tag if available
        if "element_tags" in form_data:
            element_tags = form_data.get("element_tags", {})
            if field_id in element_tags:
                tag = element_tags[field_id].lower()
                if tag == "select":
                    self.logger.debug(f"Field {field_id} identified as select from element_tags")
                    return "select"
                elif tag == "input":
                    input_type = form_data.get("input_types", {}).get(field_id, "text")
                    if input_type == "file":
                        return "file"
                    elif input_type in ["checkbox", "radio"]:
                        return "checkbox"
        
        # Check for HTML structure indicators
        html_structure = form_data.get("html_structure", {})
        if field_id in html_structure:
            field_html = html_structure.get(field_id, "").lower()
            if field_html and any(indicator in field_html for indicator in ["<select", "dropdown", "combobox"]):
                self.logger.debug(f"Field {field_id} identified as select from HTML structure")
                return "select"
            
        # Default to text
        return "text"
    
    def _get_selector_for_field(self, field_id: str, form_data: Dict[str, Any]) -> Optional[str]:
        """Get the selector for a field from form data."""
        # Check if the field has specific selector strategies in form_structure
        if "form_structure" in form_data:
            for section in form_data.get("form_structure", {}).get("sections", []):
                for field in section.get("fields", []):
                    if field.get("id") == field_id:
                        # Use the first selector strategy if available
                        strategies = field.get("selector_strategies", [])
                        
                        # School, degree, and discipline fields often need special handling
                        is_education_field = any(edu_field in field_id for edu_field in ["school", "degree", "discipline"])
                        
                        if strategies:
                            if len(strategies) > 1:
                                # If it's an education field or dropdown, try to find a better selector than just the ID
                                if is_education_field or field.get("type") == "select" or "options" in field:
                                    # Try different selector strategies
                                    for strategy in strategies:
                                        # Prefer selectors that look like complete CSS selectors rather than just IDs
                                        if strategy.startswith('#') and '--' in strategy:
                                            return strategy
                                        elif '[name=' in strategy or '[id=' in strategy:
                                            return strategy
                                
                                # Default to the second strategy (usually the ID selector)
                                return strategies[1]
                            else:
                                return strategies[0]
        
        # Check form_elements
        form_elements = form_data.get("form_elements", [])
        for element in form_elements:
            if element.get("id") == field_id:
                selector = element.get("selector")
                if selector:
                    return selector
                
                # For dropdowns, try to find a more specific selector
                if element.get("type") == "select" or "options" in element:
                    selectors = element.get("selector_strategies", [])
                    if selectors and len(selectors) > 0:
                        return selectors[0]
                
                return f"#{field_id}"  # Default to ID selector
        
        # Fall back to a simple ID selector
        return f"#{field_id}"

    def _importance_to_float(self, importance: str) -> float:
        """Convert importance string to float value."""
        importance_map = {
            "high": 1.0,
            "medium": 0.5,
            "low": 0.1
        }
        return importance_map.get(importance.lower(), 0.1)

    @staticmethod
    def create_execution_prompt(
        form_data: Dict[str, Any],
        field_mappings: Dict[str, Any],
        test_mode: bool = False
    ) -> str:
        """
        Create a prompt for executing a job application.
        
        Args:
            form_data: Form data and structure
            field_mappings: Field mappings from profile
            test_mode: Whether to run in test mode
            
        Returns:
            Execution prompt for the LLM
        """
        mode = "TEST MODE" if test_mode else "LIVE MODE"
        
        task_part = f"""
        TASK:
        Execute the following job application form in {mode}.
        """
        
        form_part = f"""
        FORM STRUCTURE:
        {json.dumps(form_data, indent=2)}
        """
        
        mappings_part = f"""
        FIELD MAPPINGS:
        {json.dumps(field_mappings, indent=2)}
        """
        
        instructions_part = """
        INSTRUCTIONS:
        1. Analyze the form structure and field mappings
        2. Create an execution plan that fills out the form efficiently
        3. Return your plan as a JSON array of steps, where each step has:
           - action: The action to take (e.g., "fill", "select", "upload")
           - field_id: The ID of the field to interact with
           - value: The value to input or select
           - options: Optional parameters for the action
        
        Example output format:
        [
            {
                "action": "fill",
                "field_id": "name",
                "value": "John Smith",
                "options": {}
            },
            {
                "action": "select",
                "field_id": "education",
                "value": "Bachelor's Degree",
                "options": {"exact_match": true}
            }
        ]
        """
        
        return task_part + form_part + mappings_part + instructions_part 

    def _get_dropdown_options(self, field_id: str, form_data: Dict[str, Any]) -> List[str]:
        """Get dropdown options for a field if available."""
        # Check form_elements
        form_elements = form_data.get("form_elements", [])
        for element in form_elements:
            if element.get("id") == field_id and "options" in element:
                return element.get("options", [])
        
        # Check in sections if available
        if "form_structure" in form_data:
            for section in form_data.get("form_structure", {}).get("sections", []):
                for field in section.get("fields", []):
                    if field.get("id") == field_id and "options" in field:
                        return field.get("options", [])
        
        # Look in validation_data
        if "validation_data" in form_data:
            field_validation = form_data.get("validation_data", {}).get(field_id, {})
            if "options" in field_validation:
                return field_validation.get("options", [])
        
        return [] 

    async def _handle_recaptcha_field(self, field_id: str, form_structure: Dict[str, Any]) -> Dict[str, Any]:
        """Handle reCAPTCHA fields specially.
        
        These fields require special handling as they're invisible and filled by the reCAPTCHA service.
        In test mode, we'll skip them; in production, we might attempt some form of workaround.
        
        Args:
            field_id: The field ID
            form_structure: The form structure
            
        Returns:
            Result dictionary
        """
        self.logger.info(f"Detected reCAPTCHA field: {field_id} - marking as handled in test mode")
        return {
            "field_id": field_id,
            "success": True,  # Pretend we handled it in test mode
            "field_type": "recaptcha",
            "value": "[RECAPTCHA FIELD - SKIPPED IN TEST MODE]",
            "error": None
        }

    def _get_field_type(self, field_id: str, form_structure: Dict[str, Any]) -> str:
        """Get the type of a form field from structure.
        
        Args:
            field_id: The field ID
            form_structure: The form structure
            
        Returns:
            Field type (e.g., 'text', 'select', 'file', 'textarea')
        """
        # First check in form_elements list
        if "form_elements" in form_structure:
            for element in form_structure.get("form_elements", []):
                if element.get("id") == field_id:
                    return element.get("type", "text")
        
        # Try to guess from HTML structure
        element_html = form_structure.get("html_structure", {}).get(field_id, "")
        
        if "textarea" in element_html.lower():
            return "textarea"
        elif 'type="file"' in element_html.lower():
            return "file"
        elif 'class="select__input"' in element_html.lower() or 'role="combobox"' in element_html.lower():
            return "select"
        elif "recaptcha" in field_id.lower() or "captcha" in field_id.lower():
            return "recaptcha"
        else:
            return "text" # Default to text input 

    async def _execute_field(self, field_id: str, field_type: str, value: str, form_structure: Dict) -> Dict[str, Any]:
        """Execute an action for a specific field.
        
        Args:
            field_id: ID of the field
            field_type: Type of the field (text, select, etc.)
            value: Value to set
            form_structure: Form structure data
            
        Returns:
            Dictionary with execution result
        """
        try:
            # Get the field's frame ID if applicable
            frame_id = self._get_field_frame(field_id, form_structure)
            
            # Format selector properly for CSS
            selector = f"#{field_id}"
            # Use attribute selector for numeric IDs
            if field_id.isdigit() or (field_id and field_id[0].isdigit()):
                selector = f"[id='{field_id}']"
            
            # Execute appropriate action based on field type
            if field_type == "select":
                # Get dropdown options from form structure
                dropdown_options = self._get_dropdown_options(field_id, form_structure)
                
                # If we have options and this is not a test run, find the best match
                if hasattr(self.action_executor, 'get_dropdown_options'):
                    # Try to get actual options from the dropdown
                    try:
                        actual_options = await self.action_executor.get_dropdown_options(selector, frame_id)
                        if actual_options:
                            self.logger.debug(f"Found {len(actual_options)} actual options for field {field_id}")
                            # Filter out non-options like descriptions or headers
                            cleaned_options = []
                            for option in actual_options:
                                # Skip extremely long text that's likely not an option
                                if len(option) < 100:
                                    cleaned_options.append(option)
                            
                            # Only use actual options if we found some valid ones
                            if cleaned_options:
                                self.logger.debug(f"Available options for {field_id}: {cleaned_options}")
                                dropdown_options = cleaned_options
                            else:
                                self.logger.warning(f"Found {len(actual_options)} options but they appear invalid for field {field_id}")
                    except Exception as e:
                        self.logger.warning(f"Could not get actual dropdown options for {field_id}: {str(e)}")
                
                # Determine the field context type for better matching
                context_type = None
                
                # Check field id for type hints
                field_id_lower = field_id.lower()
                if any(edu_term in field_id_lower for edu_term in ["school", "university", "college"]):
                    context_type = "education"
                elif any(degree_term in field_id_lower for degree_term in ["degree", "education"]):
                    context_type = "degree"
                elif any(discipline_term in field_id_lower for discipline_term in ["discipline", "major", "field", "study"]):
                    context_type = "discipline"
                elif any(location_term in field_id_lower for location_term in ["location", "city", "state", "country"]):
                    context_type = "location"
                elif any(demo_term in field_id_lower for demo_term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                    context_type = "demographic"
                
                # If dropdown options exist, try to find the best match
                if dropdown_options:
                    self.logger.debug(f"Available options for {field_id}: {dropdown_options}")
                    
                    # Special handling for location fields to improve matching
                    if context_type == "location" and "," in value:
                        # For locations like "San Francisco, California" check if any option contains both parts
                        city_state_parts = [part.strip() for part in value.split(",")]
                        if len(city_state_parts) >= 2:
                            # Try to find options that contain both parts
                            city, state = city_state_parts[0], city_state_parts[1]
                            matches = []
                            for option in dropdown_options:
                                if city.lower() in option.lower() and state.lower() in option.lower():
                                    matches.append((option, 0.9))
                            
                            # If we found matches, use the first one
                            if matches:
                                best_match, similarity = matches[0]
                                self.logger.info(f"Found location match '{best_match}' for '{value}' with {similarity:.1%} confidence")
                                value = best_match
                            else:
                                # If no combined match, try to match just the city or state
                                for part in city_state_parts:
                                    for option in dropdown_options:
                                        if part.lower() in option.lower():
                                            best_match, similarity = option, 0.7
                                            self.logger.info(f"Found partial location match '{best_match}' for '{value}' with {similarity:.1%} confidence")
                                            value = best_match
                                            break
                    
                    # First try exact match before using fuzzy matching
                    exact_match = next((option for option in dropdown_options if option.lower() == value.lower()), None)
                    if exact_match:
                        self.logger.info(f"Found exact match '{exact_match}' for '{value}'")
                        value = exact_match
                    # Special handling for Berkeley specifically in the main matching flow
                    elif "berkeley" in value.lower() and "university of california" in value.lower():
                        # Look for Berkeley in options explicitly
                        berkeley_options = []
                        for option in dropdown_options:
                            if "berkeley" in option.lower():
                                berkeley_options.append(option)
                                
                        if berkeley_options:
                            # Found a Berkeley option, use it directly
                            value = berkeley_options[0]
                            self.logger.info(f"Matched Berkeley specifically: '{value}'")
                        else:
                            # Fall back to regular matching but log the issue
                            self.logger.warning(f"Looking for Berkeley but not found in options. Will try regular matching.")
                            # Continue to regular matching below
                    
                    # If no exact match or Berkeley match, use regular matching
                    if not exact_match and not ("berkeley" in value.lower() and "university of california" in value.lower()):
                        # Use the dropdown matcher tool to find the best match
                        best_match, similarity = self.dropdown_matcher.find_best_match(
                            value, dropdown_options, field_type=context_type
                        )
                        
                        if best_match and similarity >= self.dropdown_matcher.match_threshold:
                            # Extra validation for Berkeley case to avoid false matches
                            if "berkeley" in value.lower() and "university of california" in value.lower():
                                if "berkeley" not in best_match.lower():
                                    self.logger.warning(f"Rejecting match '{best_match}' for Berkeley - doesn't contain 'berkeley'")
                                    # Look for any option containing Berkeley as a fallback
                                    berkeley_fallback = next((opt for opt in dropdown_options if "berkeley" in opt.lower()), None)
                                    if berkeley_fallback:
                                        value = berkeley_fallback
                                        self.logger.info(f"Using Berkeley fallback: '{value}'")
                                    # Otherwise continue with the original value and let the form handler deal with it
                                else:
                                    self.logger.info(f"Selected Berkeley match: '{best_match}' with {similarity:.1%} confidence")
                                    value = best_match
                            else:
                                self.logger.info(f"Selected '{best_match}' for '{value}' with {similarity:.1%} confidence")
                                value = best_match
                
                success = await self.action_executor.execute_action("select", selector, value, frame_id)
                if not success:
                    self.logger.error(f"Failed to execute select for field {field_id} of type {field_type}")
                    return {"success": False, "error": "Select action failed"}
                else:
                    self.logger.info(f"Successfully executed select for field {field_id} of type {field_type}")
                    return {"success": True}
                    
            elif field_type == "checkbox":
                # Convert value to boolean
                checked = self._parse_bool(value)
                success = await self.action_executor.execute_action("checkbox", selector, checked, frame_id)
                if not success:
                    self.logger.error(f"Failed to execute checkbox for field {field_id} of type {field_type}")
                    return {"success": False, "error": "Checkbox action failed"}
                else:
                    self.logger.info(f"Successfully executed checkbox for field {field_id} of type {field_type}")
                    return {"success": True}
                    
            elif field_type == "file":
                # Handle file uploads
                # Check if the path exists and is a file (not a directory)
                if value and not os.path.isfile(value):
                    self.logger.error(f"File path {value} for field {field_id} is not a valid file")
                    return {"success": False, "error": "Invalid file path"}
                
                success = await self.action_executor.execute_action("upload", selector, value, frame_id)
                if not success:
                    self.logger.error(f"Failed to execute file for field {field_id} of type {field_type}")
                    return {"success": False, "error": "File upload failed"}
                else:
                    self.logger.info(f"Successfully executed file for field {field_id} of type {field_type}")
                    return {"success": True}
                    
            elif field_type == "textarea":
                # Handle multiline text
                success = await self.action_executor.execute_action("fill", selector, value, frame_id)
                if not success:
                    self.logger.error(f"Failed to execute textarea for field {field_id} of type {field_type}")
                    return {"success": False, "error": "Text area fill failed"}
                else:
                    self.logger.info(f"Successfully executed textarea for field {field_id} of type {field_type}")
                    return {"success": True}
                    
            else:
                # Default to text input
                success = await self.action_executor.execute_action("fill", selector, value, frame_id)
                if not success:
                    self.logger.error(f"Failed to execute text for field {field_id} of type {field_type}")
                    return {"success": False, "error": "Text fill failed"}
                else:
                    self.logger.info(f"Successfully executed text for field {field_id} of type {field_type}")
                    return {"success": True}
                    
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations:
                unique_variations.append(v)
                
        return unique_variations
                
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two strings using multiple methods.
        
        Args:
            text1: First string to compare
            text2: Second string to compare
            
        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Normalize inputs
        norm1 = self._normalize_text(text1)
        norm2 = self._normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
            
        # Check for exact match after normalization
        if norm1 == norm2:
            return 1.0
            
        # Check if one contains the other completely
        if norm1 in norm2:
            # If the first string is entirely contained, score based on relative length
            return 0.8 + (0.2 * (len(norm1) / len(norm2)))
        elif norm2 in norm1:
            return 0.8 + (0.2 * (len(norm2) / len(norm1)))
            
        # For very short strings (like "Yes", "No"), use more strict matching
        if len(norm1) <= 3 or len(norm2) <= 3:
            return 1.0 if norm1 == norm2 else 0.0
            
        # For longer strings, use SequenceMatcher
        matcher = SequenceMatcher(None, norm1, norm2)
        ratio = matcher.ratio()
        
        # For critical demographic fields, we need exact matches for Yes/No type fields
        if norm1 in ["yes", "no"] or norm2 in ["yes", "no"]:
            # Boost exact yes/no matches, penalize mismatches
            if (norm1 == "yes" and norm2 == "yes") or (norm1 == "no" and norm2 == "no"):
                return 1.0
            elif (norm1 == "yes" and norm2 == "no") or (norm1 == "no" and norm2 == "yes"):
                return 0.0
                
        # If the strings share many words, boost their similarity
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        if words1 and words2:
            common_words = words1.intersection(words2)
            word_overlap = len(common_words) / max(len(words1), len(words2))
            
            # Use a weighted average of sequence ratio and word overlap
            ratio = (ratio * 0.6) + (word_overlap * 0.4)
            
        return ratio
            
    def _find_best_dropdown_match(self, target_value: str, available_options: List[str], field_id: str = "", field_type: str = "select") -> Tuple[Optional[str], float]:
        """Find the best matching option from available dropdown options.
        
        Args:
            target_value: The value we want to match
            available_options: List of available dropdown options
            field_id: ID of the field (for context-aware matching)
            field_type: Type of the field (for specialized matching)
            
        Returns:
            Tuple of (best_match, confidence_score)
        """
        if not target_value or not available_options:
            return None, 0.0
            
        # Generate variations for the target value based on field type
        context_type = field_type
        if field_id:
            if "school" in field_id or "university" in field_id or "college" in field_id:
                context_type = "education"
            elif any(term in field_id for term in ["gender", "ethnicity", "race", "veteran", "disability", "lgbtq"]):
                context_type = "demographic"
            elif "degree" in field_id:
                context_type = "degree"
                
        target_variations = self._generate_variations(target_value, context_type)
        
        best_match = None
        best_score = 0.0
        match_details = []
        
        # For critical demographic fields with simple Yes/No or binary options, 
        # handle more carefully to avoid misrepresenting the user
        is_binary_field = any(term in field_id for term in ["gender", "ethnicity", "veteran", "disability", "lgbtq"])
        
        # For binary fields, determine if user intent is Yes/No/Prefer not to say
        user_intent = None
        if is_binary_field:
            normalized_target = self._normalize_text(target_value)
            if normalized_target in ["yes", "true", "y", "1"]:
                user_intent = "yes"
            elif normalized_target in ["no", "false", "n", "0"]:
                user_intent = "no"
            elif "decline" in normalized_target or "prefer not" in normalized_target or "don't wish" in normalized_target:
                user_intent = "decline"
        
        # First pass: Try exact matches and high-confidence matches
        for option in available_options:
            for variation in target_variations:
                similarity = self._calculate_similarity(variation, option)
                match_details.append((option, variation, similarity))
                
                # If it's a binary field, check if option aligns with user intent
                if is_binary_field and user_intent:
                    option_normalized = self._normalize_text(option)
                    
                    # Check if option matches user intent
                    if user_intent == "yes" and any(kw in option_normalized for kw in ["yes", "identify", "have", "am"]) and not any(neg in option_normalized for neg in ["not", "no ", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost positive matches
                    elif user_intent == "no" and any(kw in option_normalized for kw in ["no", "not", "don't", "do not"]):
                        similarity = max(similarity, 0.85)  # Boost negative matches
                    elif user_intent == "decline" and any(kw in option_normalized for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        similarity = max(similarity, 0.9)  # Boost decline matches
                        
                    # Avoid selecting contradictions to user intent
                    if (user_intent == "yes" and any(kw in option_normalized for kw in ["no", "not ", "don't", "do not"])) or \
                       (user_intent == "no" and option_normalized.startswith("yes")):
                        similarity = min(similarity, 0.4)  # Penalize contradictory matches
                
                if similarity > best_score:
                    best_score = similarity
                    best_match = option
                    
                    # If we have a very strong match, just use it
                    if similarity > 0.95:
                        break
            
            # Early exit if we found a very strong match
            if best_score > 0.95:
                break
                
        # Log detailed matching information
        self.logger.debug(f"Match details for field '{field_id}' with target '{target_value}':")
        for option, variation, score in sorted(match_details, key=lambda x: x[2], reverse=True)[:5]:
            self.logger.debug(f"  - Option: '{option}', variation: '{variation}', score: {score:.2f}")
            
        # Set a minimum threshold to avoid poor matches
        # Use a higher threshold for critical fields
        threshold = 0.7  # Default threshold
        if is_binary_field:
            threshold = 0.75  # Higher threshold for demographic fields
            
        if best_score < threshold:
            self.logger.warning(f"No good match found for '{target_value}' in field '{field_id}'. Best option '{best_match}' with score {best_score:.2f} is below threshold {threshold:.2f}")
            # For truly binary fields (Yes/No), fallback to safest option if no good match
            if is_binary_field and len(available_options) <= 3:
                # Look for a "prefer not to say" or similar option as fallback
                for option in available_options:
                    opt_norm = self._normalize_text(option)
                    if any(kw in opt_norm for kw in ["decline", "prefer not", "don't wish", "do not wish"]):
                        self.logger.info(f"Falling back to '{option}' as a safe option for field '{field_id}'")
                        return option, 0.5  # Use a modest confidence score
        else:
            self.logger.info(f"Selected '{best_match}' for '{target_value}' with {best_score:.2f} confidence")
            
            # Special case for "Closest Match" placeholder
            if value.lower() == "closest match" or value.lower() == "closest match from dropdown options":
                # For demographic fields, we might need to make a reasonable guess
                if context_type == "demographic":
                    # For binary options like Yes/No, prefer No as it's safer
                    safe_options = []
                    for option in dropdown_options:
                        option_lower = option.lower()
                        if any(term in option_lower for term in ["no", "false", "i am not", "not a", "do not", "don't", "decline", "prefer not"]):
                            safe_options.append(option)
                    
                    if safe_options:
                        value = safe_options[0]
                        self.logger.info(f"Selected safe default '{value}' for placeholder value in demographic field")
                    else:
                        # If no obvious safe option, use the first option as fallback
                        value = dropdown_options[0]
                        self.logger.info(f"Using first option '{value}' for placeholder")
                # Special case for education fields - try to match University of California, Berkeley specifically
                elif context_type == "education" and field_id_lower.startswith("school"):
                    berkeley_match = None
                    # Look for Berkeley specifically
                    for option in dropdown_options:
                        if "berkeley" in option.lower():
                            berkeley_match = option
                            break
                    
                    # If we found Berkeley, use it
                    if berkeley_match:
                        value = berkeley_match
                        self.logger.info(f"Selected Berkeley match '{value}' for education field")
                    else:
                        self.logger.warning(f"No Berkeley match found in education options")
                        if dropdown_options:
                            value = dropdown_options[0]
                else:
                    self.logger.warning(f"No good match found for placeholder '{value}'. Options: {dropdown_options}")
                    # Use first option as fallback if no good match found
                    if dropdown_options:
                        value = dropdown_options[0]
            else:
                # Regular value with no good match
                self.logger.warning(f"No good match found for '{value}'. Best match: '{best_match}' with {similarity:.1%} confidence")
                # If no good match but we have a best match with some similarity, still use it
                if best_match and similarity > 0.4:  # Lower threshold for fallback
                    self.logger.info(f"Using best available match '{best_match}' with {similarity:.1%} confidence")
                    value = best_match
        except Exception as e:
            error_message = f"Error executing field {field_id}: {str(e)}"
            self.logger.error(error_message)
            return {"success": False, "error": error_message}

    def _get_field_frame(self, field_id: str, form_structure: Dict) -> Optional[str]:
        """Get the frame ID for a field if it exists in a frame.
        
        Args:
            field_id: ID of the field
            form_structure: Form structure data
            
        Returns:
            Frame ID or None if field is in the main frame
        """
        # Check if form structure has frame data
        if "frames" in form_structure:
            # Search for the field in each frame
            for frame_id, frame_data in form_structure.get("frames", {}).items():
                if "fields" in frame_data:
                    # Check if field exists in this frame's fields
                    if field_id in frame_data["fields"]:
                        return frame_id
        
        # Field is in the main frame
        return None
        
    def _parse_bool(self, value: Any) -> bool:
        """Parse a value as boolean.
        
        Args:
            value: Value to parse
            
        Returns:
            Boolean value
        """
        if isinstance(value, bool):
            return value
            
        if isinstance(value, str):
            return value.lower() in ("yes", "true", "t", "1", "on", "y")
            
        if isinstance(value, (int, float)):
            return bool(value)
            
        # Default to False for None or other types
        return False 

    def _normalize_text(self, text: str) -> str:
        """Normalize text for comparison by removing special chars, extra spaces, and converting to lowercase."""
        if not text:
            return ""
        # Convert to lowercase
        normalized = text.lower()
        # Replace special characters with spaces
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        # Replace multiple spaces with a single space
        normalized = re.sub(r'\s+', ' ', normalized)
        # Remove leading/trailing whitespace
        return normalized.strip()
        
    def _generate_variations(self, text: str, field_type=None) -> List[str]:
        """Generate common variations of text for better matching.
        
        Args:
            text: The original text to generate variations for
            field_type: Optional type of field to help with specialized variations
            
        Returns:
            List of variations including the original text
        """
        if not text:
            return []
            
        variations = [text]  # Always include original
        normalized = self._normalize_text(text)
        variations.append(normalized)
        
        # Skip further processing for very simple inputs like "Yes" or "No"
        if len(normalized) <= 3:
            return variations
            
        # Handle different field types with specialized variations
        if field_type == "education" or "school" in field_type or "university" in field_type:
            # University name variations
            
            # Extract core identifiers (e.g., "Berkeley" from "University of California, Berkeley")
            # This is critical for finding matches when full name isn't in the list
            parts = normalized.split()
            
            # Try to extract the most distinctive part (usually after commas or "at" or last word)
            distinctive_parts = []
            
            # Check for parts after comma
            if "," in text:
                distinctive_parts.extend([p.strip() for p in text.split(",")[1:]])
            
            # Check for distinctive keywords that often follow the main institution name
            for i, part in enumerate(parts):
                if i > 0 and parts[i-1] in ["at", "of"]:
                    distinctive_parts.append(part)
                
            # Add last part as it's often distinctive (e.g., "Berkeley")
            if len(parts) > 1:
                distinctive_parts.append(parts[-1])
                
            # Add distinctive parts and their variations to our list
            for part in distinctive_parts:
                clean_part = self._normalize_text(part)
                if len(clean_part) > 3:  # Only add if substantial
                    variations.append(clean_part)
            
            # Common university abbreviation patterns
            if "university" in normalized:
                # Replace "university" with "univ"
                variations.append(normalized.replace("university", "univ"))
                
                # Try to create abbreviation (e.g., "UCLA", "USC", "UCB")
                if "university of" in normalized:
                    initials = ""
                    name_parts = normalized.replace("university of", "").strip().split()
                    if name_parts:
                        # Add abbreviated form like "UC Berkeley"
                        if len(name_parts) > 1:
                            variations.append(f"u{name_parts[0][0]} {name_parts[-1]}")
                        # Create initials like "UCB"
                        for part in name_parts:
                            if part and len(part) > 2:  # Skip small words
                                initials += part[0]
                        if initials:
                            variations.append(f"u{initials}")
            
            # Try without "University/College/Institute of" prefix
            for prefix in ["university of", "college of", "institute of"]:
                if normalized.startswith(prefix):
                    variations.append(normalized[len(prefix):].strip())
                    
        elif field_type == "demographic" or any(kw in field_type for kw in ["gender", "ethnicity", "veteran", "disability"]):
            # Boolean-like variations for demographics
            if normalized in ["yes", "true", "y", "1"]:
                variations.extend(["yes", "y", "true", "1"])
            elif normalized in ["no", "false", "n", "0"]:
                variations.extend(["no", "n", "false", "0"])
                
            # For more complex demographic answers, include word stems
            # E.g. "not a veteran" should match things containing "not" and "veteran"
            words = normalized.split()
            if len(words) > 1:
                key_terms = [w for w in words if len(w) > 3 and w not in ["have", "has", "had", "the", "and", "this", "that"]]
                variations.extend(key_terms)
        
        # Special handling for degree fields
        elif field_type == "degree":
            if "bachelor" in normalized:
                variations.extend(["bachelor", "bachelor's", "bachelors", "bs", "ba", "b.s.", "b.a."])
            elif "master" in normalized:
                variations.extend(["master", "master's", "masters", "ms", "ma", "m.s.", "m.a."])
            elif "doctor" in normalized or "phd" in normalized:
                variations.extend(["doctor", "doctoral", "doctorate", "phd", "ph.d.", "ph d"])
                
        # Remove duplicates while preserving order
        unique_variations = []
        for v in variations:
            if v and v not in unique_variations: